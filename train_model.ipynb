{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e982e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66e982e8",
    "outputId": "5fb4c22b-7ac4-4141-f57a-53d2763f2360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.8)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/lib/python3/dist-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "%pip install matplotlib tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c789e96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.8.0+cu128\n",
      "------------------------------\n",
      "CUDA Version: 12.8\n",
      "------------------------------\n",
      "GPU 0: NVIDIA GeForce RTX 5090\n",
      "VRAM: 31.37 GB\n"
     ]
    }
   ],
   "source": [
    "# Get setup info\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    # Calculate VRAM in GB\n",
    "    vram_gb = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    # Use the calculated variable here\n",
    "    print(f\"VRAM: {vram_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc989e",
   "metadata": {
    "id": "4cfc989e"
   },
   "source": [
    "### Estimate ideal loss on the dataset a priori\n",
    "\n",
    "Use strong compression algorithm to estimated the theoretical loss lower bound:\n",
    "\n",
    "$$\\text{Ideal Loss} \\approx \\frac{\\text{Compressed Bits}}{N} \\times \\ln(2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5793a2af",
   "metadata": {
    "id": "5793a2af"
   },
   "outputs": [],
   "source": [
    "# define a sinple BPE tokenizer\n",
    "import re\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "class SimpleBPE:\n",
    "    \"\"\"\n",
    "    Simple Byte Pair Encoding tokenizer.\n",
    "    Trains custom vocabulary on your text data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vocab = {}           # token_id -> token_string\n",
    "        self.vocab_inv = {}       # token_string -> token_id\n",
    "        self.merges = []          # list of merge rules\n",
    "        self.special_tokens = {}\n",
    "        self.max_token_len = 1    # for fast encoding\n",
    "\n",
    "    def _get_stats(self, token_seqs):\n",
    "        \"\"\"Count frequency of adjacent pairs.\"\"\"\n",
    "        pairs = Counter()\n",
    "        for seq in token_seqs:\n",
    "            for i in range(len(seq) - 1):\n",
    "                pairs[(seq[i], seq[i + 1])] += 1\n",
    "        return pairs\n",
    "\n",
    "    def _merge_pair(self, token_seqs, pair, new_token):\n",
    "        \"\"\"Merge all occurrences of pair into new_token.\"\"\"\n",
    "        new_seqs = []\n",
    "        for seq in token_seqs:\n",
    "            new_seq = []\n",
    "            i = 0\n",
    "            while i < len(seq):\n",
    "                if i < len(seq) - 1 and seq[i] == pair[0] and seq[i + 1] == pair[1]:\n",
    "                    new_seq.append(new_token)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_seq.append(seq[i])\n",
    "                    i += 1\n",
    "            new_seqs.append(new_seq)\n",
    "        return new_seqs\n",
    "\n",
    "    def train(self, text, vocab_size=1000, verbose=True):\n",
    "        \"\"\"Train BPE on the given text.\"\"\"\n",
    "        if verbose:\n",
    "            print(f\"Training BPE tokenizer on {len(text):,} characters...\")\n",
    "\n",
    "        # Split into words (keep whitespace attached)\n",
    "        words = re.findall(r'\\S+|\\s+', text)\n",
    "        token_seqs = [[c for c in word] for word in words]\n",
    "\n",
    "        # Initial vocabulary = unique characters\n",
    "        chars = sorted(set(text))\n",
    "        self.vocab = {i: c for i, c in enumerate(chars)}\n",
    "        self.vocab_inv = {c: i for i, c in enumerate(chars)}\n",
    "        next_id = len(chars)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Base vocabulary: {len(chars)} characters\")\n",
    "\n",
    "        # Convert to token IDs\n",
    "        token_seqs = [[self.vocab_inv[c] for c in seq] for seq in token_seqs]\n",
    "\n",
    "        # Iteratively merge most frequent pairs\n",
    "        self.merges = []\n",
    "        num_merges = vocab_size - len(chars)\n",
    "\n",
    "        for i in range(num_merges):\n",
    "            stats = self._get_stats(token_seqs)\n",
    "            if not stats:\n",
    "                break\n",
    "\n",
    "            best_pair = max(stats, key=stats.get)\n",
    "            new_token_str = self.vocab[best_pair[0]] + self.vocab[best_pair[1]]\n",
    "\n",
    "            self.vocab[next_id] = new_token_str\n",
    "            self.vocab_inv[new_token_str] = next_id\n",
    "            self.merges.append(best_pair)\n",
    "\n",
    "            token_seqs = self._merge_pair(token_seqs, best_pair, next_id)\n",
    "\n",
    "            if verbose and (i + 1) % 200 == 0:\n",
    "                print(f\"  {i+1}/{num_merges} merges completed...\")\n",
    "\n",
    "            next_id += 1\n",
    "\n",
    "        # Set max token length for fast encoding\n",
    "        self.max_token_len = max(len(t) for t in self.vocab.values())\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Training complete! Vocabulary size: {len(self.vocab)}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def add_special_token(self, token_str):\n",
    "        \"\"\"Add a special token like <MASK>.\"\"\"\n",
    "        token_id = len(self.vocab)\n",
    "        self.vocab[token_id] = token_str\n",
    "        self.vocab_inv[token_str] = token_id\n",
    "        self.special_tokens[token_str] = token_id\n",
    "        self.max_token_len = max(self.max_token_len, len(token_str))\n",
    "        return token_id\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"\n",
    "        Fast encoding using greedy longest-match.\n",
    "        O(max_token_len * text_len) instead of O(num_merges * text_len)\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        i = 0\n",
    "        n = len(text)\n",
    "\n",
    "        while i < n:\n",
    "            # Try longest match first, then shorter\n",
    "            for length in range(min(self.max_token_len, n - i), 0, -1):\n",
    "                substr = text[i:i + length]\n",
    "                if substr in self.vocab_inv:\n",
    "                    tokens.append(self.vocab_inv[substr])\n",
    "                    i += length\n",
    "                    break\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown character at position {i}: {repr(text[i])}\")\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def decode(self, token_ids):\n",
    "        \"\"\"Decode token IDs back to text.\"\"\"\n",
    "        return ''.join(self.vocab[i] for i in token_ids)\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"Save tokenizer to file.\"\"\"\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump({\n",
    "                'vocab': {str(k): v for k, v in self.vocab.items()},\n",
    "                'merges': self.merges,\n",
    "                'special_tokens': self.special_tokens,\n",
    "                'max_token_len': self.max_token_len\n",
    "            }, f)\n",
    "        print(f\"Tokenizer saved to {path}\")\n",
    "\n",
    "    def load(self, path):\n",
    "        \"\"\"Load tokenizer from file.\"\"\"\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        self.vocab = {int(k): v for k, v in data['vocab'].items()}\n",
    "        self.vocab_inv = {v: k for k, v in self.vocab.items()}\n",
    "        self.merges = [tuple(m) for m in data['merges']]\n",
    "        self.special_tokens = data.get('special_tokens', {})\n",
    "        self.max_token_len = data.get('max_token_len', max(len(t) for t in self.vocab.values()))\n",
    "        print(f\"Tokenizer loaded from {path} (vocab size: {len(self.vocab)})\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cccd529",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cccd529",
    "outputId": "410faffa-3410-4d8b-b29d-9e42bf6f9fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded from tokenizer_bpe.json (vocab size: 8192)\n",
      "Vocabulary size: 8192 tokens\n",
      "Maske token id: 8191\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer (train the tokenizer separately)\n",
    "\n",
    "tokenizer = SimpleBPE().load('tokenizer_bpe.json')\n",
    "\n",
    "print(f'Vocabulary size: {len(tokenizer.vocab)} tokens')\n",
    "print(f'Maske token id: {tokenizer.special_tokens.get(\"<MASK>\", \"Not found\")}')\n",
    "\n",
    "# use tokenizer\n",
    "def encode(text): return tokenizer.encode(text)\n",
    "def decode(ids): return tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c99f039",
   "metadata": {
    "id": "9c99f039"
   },
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "\n",
    "class DLMDataset(Dataset):\n",
    "    def __init__(self, data, block_size, samples_per_epoch=20000):\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "        self.sample_per_epoch = samples_per_epoch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sample_per_epoch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = torch.randint(0, len(self.data) - self.block_size, (1,)).item()\n",
    "        chunk = self.data[start_idx : start_idx + self.block_size]\n",
    "        return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2510661b",
   "metadata": {
    "id": "2510661b"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "block_size = 512\n",
    "final_vocab_size = len(tokenizer.vocab)\n",
    "batch_size = 128\n",
    "n_embd = 512\n",
    "n_head = 4\n",
    "n_blocks = 6\n",
    "MASK_TOKEN = tokenizer.special_tokens.get('<MASK>', 'Not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c4fb5f-3fd0-4889-9364-337b09b8e25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of logical CPUs (threads): 128\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cpu_count = os.cpu_count()\n",
    "print(f\"Number of logical CPUs (threads): {cpu_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0159595",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0159595",
    "outputId": "f634643e-1ed1-424a-d924-cc5e606123c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([128, 512])\n",
      "Sample decoded:\n",
      " them; Harry took one glance back at the thestrals, now foraging for scraps of rotten food inside the dumpster, then forced himself into the box after Luna.\n",
      "“Whoever’s nearest the receiver, dial six two four four two!” he said.\n",
      "Ron did it, his arm bent bizarrely to reach the dial. As it whirred back into place the cool female voice sounded inside the box, “Welcome to the Ministry of Magic. Please state your name and business.”\n",
      "“Harry Potter, Ron Weasley, Hermione Granger,” Harry said very quickly, “Ginny Weasley, Neville Longbottom, Luna Lovegood . . . We’re here to save someone, unless your Ministry can do it first!”\n",
      "“Thank you,” said the cool female voice. “Visitors, please take the badges and attach them to the front of your robes.”\n",
      "Half a dozen badges slid out of the metal chute where returned coins usually appeared. Hermione scooped them up and handed them mutely to Harry over Ginny’s head; he glanced at the topmost one.\n",
      "HARRY POTTER\n",
      "RESCUE MISSION\n",
      "“Visitor to the Ministry, you are required to submit to a search and present your wand for registration at the security desk, which is located at the far end of the Atrium.”\n",
      "“Fine!” Harry said loudly, as his scar gave another throb. “Now can we move?”\n",
      "The floor of the telephone box shuddered and the pavement rose up ...\n"
     ]
    }
   ],
   "source": [
    "# Load pre-encoded tensor (instead of raw text)\n",
    "data_tensor = torch.load('encoded_data.pt')\n",
    "\n",
    "dataset = DLMDataset(data_tensor, block_size)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=16, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "print(f'Batch shape: {batch.shape}')\n",
    "print(f'Sample decoded:\\n{\"\".join(decode(batch[0].tolist()))}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25bbe1d8",
   "metadata": {
    "id": "25bbe1d8"
   },
   "outputs": [],
   "source": [
    "# Token Masking\n",
    "\n",
    "def mask_tokens(x_0, t, mask_token_id):\n",
    "\n",
    "    # the random value mask to apply to input tensor conditional on the prob t tensor\n",
    "    # torch.rand_like creates random values of uniform distribution in [0, 1)\n",
    "    rand = torch.rand_like(x_0, dtype=torch.float) # [B, T]\n",
    "\n",
    "    # mask where rand < t\n",
    "    mask = rand < t.unsqueeze(1) # t.unsqueeze(1) shape [B, 1]\n",
    "\n",
    "    # apply mask\n",
    "    x_t = x_0.clone() # create a copy not a reference\n",
    "    x_t[mask] = mask_token_id\n",
    "\n",
    "    # x_t --> input\n",
    "    # x_0 --> target\n",
    "\n",
    "    return x_t, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b79e8e",
   "metadata": {
    "id": "48b79e8e"
   },
   "source": [
    "The loss function is:\n",
    "\n",
    "$$\\mathcal{L}_{\\text{NELBO}} = \\mathbb{E}_{q} \\int_{0}^{1} \\frac{\\alpha'_t}{1-\\alpha_t} \\sum \\log \\langle x_\\theta(z_t), x \\rangle dt$$\n",
    "\n",
    "To break it down:\n",
    "\n",
    "$$\n",
    "\\underbrace{\\mathcal{L}_{\\text{NELBO}}}_{\\text{The Loss}} = \\underbrace{\\mathbb{E}_{q}}_{\\text{1. Batching}} \\underbrace{\\int_{0}^{1}}_{\\text{2. Sampling } t} \\underbrace{\\frac{\\alpha'_t}{1-\\alpha_t}}_{\\text{3. Weighting}} \\underbrace{\\sum \\log \\langle x_\\theta(z_t), x \\rangle dt}_{\\text{4. Cross Entropy}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Batching\n",
    "\n",
    "$$\\mathbb{E}_{q}$$\n",
    "\n",
    "More training steps means the model gets to see more complete data distribution\n",
    "\n",
    "---\n",
    "\n",
    "### Sampling\n",
    "\n",
    "$$\\int_{0}^{1} \\dots dt$$\n",
    "\n",
    "By picking a random t for every single training step, we're doing Monte Carlo simulation over the course of training, and eventually cover the whole integral from t = 0 to t = 1\n",
    "\n",
    "---\n",
    "\n",
    "### Weighting\n",
    "\n",
    "$$\\frac{\\alpha'_t}{1-\\alpha_t}$$\n",
    "\n",
    "$1-\\alpha_t$: The probability that the token is masked\n",
    "\n",
    "$\\alpha'_t$: The Rate of Destruction\n",
    "\n",
    "Together, the term is measuring signal over noise\n",
    "\n",
    "Becasue t = $1-\\alpha_t$\n",
    "\n",
    "$\\frac{\\alpha'_t}{1-\\alpha_t} \\propto \\frac{1}{t}$: equivalent to calculating avg masked loss\n",
    "\n",
    "* $\\frac{\\alpha'_t}{1-\\alpha_t}$ can also serve as logit stablizer. when t is close to 0, this term is large, which boosts gradient for the model to learn faster (less corrupted data); when t is close to 1, this terms is small, but ce_loss is large (because almost all tokens are masked, the model is taking blind guesses), this term quiets down the noises\n",
    "\n",
    "---\n",
    "\n",
    "### Cross Entropy\n",
    "\n",
    "$$\\log \\langle x_\\theta(z_t), x \\rangle$$\n",
    "\n",
    "calculating cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498a6f1f",
   "metadata": {
    "id": "498a6f1f"
   },
   "outputs": [],
   "source": [
    "## Loss function\n",
    "\n",
    "def compute_loss(model, x_0, mask_token_id):\n",
    "    B, T = x_0.shape\n",
    "\n",
    "    t = torch.rand(B, device=x_0.device).clamp_min(1e-3)  # avoid crazy 1/t; Size([B])\n",
    "    x_t, mask = mask_tokens(x_0, t, mask_token_id) # [B, T]\n",
    "\n",
    "    logits = model(x_t, t) # [B, T, V]\n",
    "    logits[:, :, mask_token_id] = -float('inf')  # Prevent predicting the mask token\n",
    "\n",
    "    logits_flat = logits.view(-1, logits.size(-1)) # [B*T, V]\n",
    "    targets_flat = x_0.view(-1) # [B*T]\n",
    "\n",
    "    # Cross entropy loss at all tokens\n",
    "    # reduction='none' means the loss stays a tensor\n",
    "    # loss.shape: [B*T]\n",
    "    ce_loss = F.cross_entropy(logits_flat, targets_flat, reduction='none').view(B, T) # [B, T]\n",
    "\n",
    "    # element-wise multiplication\n",
    "    # mask.float() turn 'True's into 1.0 and 'False's into 0.0\n",
    "    masked_loss_sum = (ce_loss * mask.float()).sum(dim=1) # [B]\n",
    "\n",
    "    # scale masked_loss_sum with 1/t on each batch indepentently --CRITICAL\n",
    "    # so that high masked and low masked rate examples contribute to loss of this batch roughly equally\n",
    "    # essentially: scale loss with 1/t --> mean()\n",
    "    # NOT: mean() --> scale loss\n",
    "    loss = ((1.0 / t) * masked_loss_sum).mean() / T\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c047b",
   "metadata": {
    "id": "ff9c047b"
   },
   "source": [
    "$$PE_{(t, 2i)} = \\sin\\left(\\frac{t \\cdot 1000}{10000^{2i/d}}\\right)$$\n",
    "\n",
    "$$PE_{(t, 2i+1)} = \\cos\\left(\\frac{t \\cdot 1000}{10000^{2i/d}}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621e616",
   "metadata": {
    "id": "b621e616"
   },
   "source": [
    "**We want:**\n",
    "$$\n",
    "\\frac{t \\cdot 1000}{10000^{\\frac{2j}{d}}}\n",
    "$$\n",
    "\n",
    "**The Code Derivation:**\n",
    "\n",
    "$$\n",
    "\\text{math.log(10000)/(half\\_dim - 1)} = \\frac{\\ln(10000)}{\\frac{d}{2} - 1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{torch.arange(half\\_dim)} = \\left[0, 1, 2, ..., \\frac{d}{2}-1\\right] = j\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{torch.arange(half\\_dim) * -emb} = -\\frac{j}{\\frac{d}{2}-1} \\cdot \\ln(10000)\n",
    "$$\n",
    "\n",
    "**Because** $e^{a\\ln(b)} = b^a \\rightarrow$\n",
    "\n",
    "$$\n",
    "e^{-\\frac{j}{d/2-1} \\cdot \\ln(10000)} = 10000^{-\\frac{j}{d/2-1}} = \\frac{1}{10000^{\\frac{2j}{d-2}}}\n",
    "$$\n",
    "\n",
    "**Final Broadcast Step:**\n",
    "\n",
    "$$\n",
    "\\text{emb} = t[:, \\text{None}] * \\text{emb}[\\text{None}, :] * 1000\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{t \\cdot 1000}{10000^{\\frac{2j}{d-2}}}\n",
    "$$\n",
    "\n",
    "Code uses `half_dim - 1` to ensure the geometric sequence is inclusive of the final endpoint. That's why the end equation has `d - 2` not `d` as the original sinusoidal PE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bffb94e6",
   "metadata": {
    "id": "bffb94e6"
   },
   "outputs": [],
   "source": [
    "# time embedding\n",
    "\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t.unsqueeze(1) * emb.unsqueeze(0) * 1000 # [B, 1] * [1, half_dim] = [B, half_dim]\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1) # [B, dim]\n",
    "\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8103da93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "8103da93",
    "outputId": "c66c859d-fa4c-499b-ed03-8f8e350259a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time embedding shape: torch.Size([5, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "time_emb = SinusoidalTimeEmbedding(64)\n",
    "t_test = torch.tensor([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "emb = time_emb(t_test)\n",
    "print(f\"Time embedding shape: {emb.shape}\")  # [5, 64]\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.imshow(emb.detach().numpy(), aspect='auto', cmap='RdBu')\n",
    "plt.xlabel('Embedding dimension')\n",
    "plt.ylabel('Time t')\n",
    "plt.yticks(range(5), ['t=0.0', 't=0.25', 't=0.5', 't=0.75', 't=1.0'])\n",
    "plt.colorbar(label='Value')\n",
    "plt.title('Sinusoidal Time Embeddings')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "088e4a9f-06ba-4fb6-82cb-cf10802add97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtune in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
      "Requirement already satisfied: torchao in /usr/local/lib/python3.12/dist-packages (0.14.1)\n",
      "Requirement already satisfied: torchdata==0.11.0 in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.11.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from torchtune) (4.4.1)\n",
      "Requirement already satisfied: huggingface_hub[hf_transfer] in /usr/local/lib/python3.12/dist-packages (from torchtune) (1.2.3)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.7.0)\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.3.13)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.2.1)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.12.0)\n",
      "Requirement already satisfied: blobfile>=2 in /usr/local/lib/python3.12/dist-packages (from torchtune) (3.1.0)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from torchtune) (0.22.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtune) (2.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtune) (4.67.1)\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from torchtune) (2.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from torchtune) (7.1.0)\n",
      "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.12/dist-packages (from torchtune) (11.0.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.12/dist-packages (from torchdata==0.11.0->torchtune) (2.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchdata==0.11.0->torchtune) (2.32.5)\n",
      "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.12/dist-packages (from torchdata==0.11.0->torchtune) (2.8.0+cu128)\n",
      "Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.12/dist-packages (from blobfile>=2->torchtune) (3.23.0)\n",
      "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.12/dist-packages (from blobfile>=2->torchtune) (6.0.2)\n",
      "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.12/dist-packages (from blobfile>=2->torchtune) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2->torchdata==0.11.0->torchtune) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (0.70.18)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets->torchtune) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->torchtune) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets->torchtune) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets->torchtune) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets->torchtune) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets->torchtune) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets->torchtune) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (0.20.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->torchtune) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->torchtune) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->torchtune) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->torchtune) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->torchtune) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->torchtune) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->torchtune) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata==0.11.0->torchtune) (3.4.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets->torchtune) (1.3.1)\n",
      "\u001b[33mWARNING: huggingface-hub 1.2.3 does not provide the extra 'hf-transfer'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2->torchdata==0.11.0->torchtune) (3.0.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->torchtune) (4.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->torchtune) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->torchtune) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->torchtune) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->torchtune) (2025.11.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub[hf_transfer]->torchtune) (8.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchtune torchao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77208d3c-9624-49f1-9641-acddccaefec9",
   "metadata": {
    "id": "63e357f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info\n"
     ]
    }
   ],
   "source": [
    "# MHA\n",
    "from torchtune.modules import RotaryPositionalEmbeddings\n",
    "# torchtune RopE implementation expects input shape [B, T, n_head, head_dim], matches the code below\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, n_embd, n_head, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert n_embd % n_head == 0\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.n_embd = n_embd\n",
    "        self.head_dim = n_embd // n_head\n",
    "\n",
    "        self.c_attn = nn.Linear(n_embd, 3*n_embd)\n",
    "        self.c_proj = nn.Linear(n_embd, n_embd)\n",
    "\n",
    "        self.rope = RotaryPositionalEmbeddings(dim=n_embd // n_head)\n",
    "\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.residual_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        # atten_c: [n_embd, 3*n_embd];\n",
    "        # x: [B, T, n_embd];\n",
    "        # attn_c(x): [B, T, n_embd]@[n_embd, 3*n_embd]=[B, T, 3*n_embd]\n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2) # [B, T, 3*n_embd] ==> 3 * [B, T, n_embd]\n",
    "\n",
    "        q = q.view(B, T, self.n_head, self.head_dim) # [B, T, n_embd] = [B, T, n_head*head_dim] ==> [B, T, n_head, head_dim]\n",
    "        # apply RoPE before transpose\n",
    "        q = self.rope(q)\n",
    "        q = q.transpose(1, 2) # [B, n_head, T, head_dim]\n",
    "        k = k.view(B, T, self.n_head, self.head_dim)\n",
    "        k = self.rope(k)\n",
    "        k = k.transpose(1, 2) # [B, n_head, T, head_dim]\n",
    "        v = v.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # k.transpose(-2, -1).shape: [B, n_head, head_dim, T]\n",
    "        # (q @ k.transpose(-2, -1)).shape: [B, n_head, T, head_dim]@[B, n_head, head_dim, T] = [B, n_head, T, T]\n",
    "        attn = (q @ k.transpose(-2, -1)*(1.0 / math.sqrt(self.head_dim))) # [B, n_head, T, T]\n",
    "\n",
    "        # No causal mask\n",
    "\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        attn = self.attn_dropout(attn)\n",
    "\n",
    "        out = attn @ v # [B, n_head, T, T]@[B, n_head, T, head_dim] = [B, n_head, T, head_dim]\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        # drop out on the residual stream\n",
    "        out = self.residual_dropout(self.c_proj(out)) # [B, T, C]@[C, C]=[B, T, C]\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "164285fb",
   "metadata": {
    "id": "164285fb"
   },
   "outputs": [],
   "source": [
    "class SwiGLU(nn.Module):\n",
    "    \"\"\"\n",
    "    SwiGLU activation function.\n",
    "\n",
    "    This effectively implements:\n",
    "    SwiGLU(x) = (xW + b) * SiLU(xV + c)\n",
    "\n",
    "    Where the input is split into two parts: one for the 'value' path\n",
    "    and one for the 'gate' path.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        # Split the input tensor into two halves along the last dimension\n",
    "        x, gate = x.chunk(2, dim=-1)\n",
    "        # Apply SiLU (Swish) to the gate and multiply with the value\n",
    "        return x * F.silu(gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edcef24b",
   "metadata": {
    "id": "edcef24b"
   },
   "outputs": [],
   "source": [
    "# FFN\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, n_embd, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(n_embd, 8*n_embd)\n",
    "        self.swiglu = SwiGLU()\n",
    "        self.c_proj = nn.Linear(4*n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x) # [B, T, C]@[C, 4*C]=[B, T, 4*C]\n",
    "        x = self.swiglu(x)\n",
    "        x = self.c_proj(x) # [B, T, 4*C]@[4*C, C]=[B, T, C]\n",
    "        x = self.dropout(x) # [B, T, C]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27d4a9ab",
   "metadata": {
    "id": "27d4a9ab"
   },
   "outputs": [],
   "source": [
    "# Block\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head, dropout=0.1, use_time=True):\n",
    "        super().__init__()\n",
    "        self.use_time = use_time\n",
    "        self.rms_norm_1 = nn.RMSNorm(n_embd)\n",
    "        self.rms_norm_2 = nn.RMSNorm(n_embd)\n",
    "        self.attn = MHA(n_embd, n_head, dropout)\n",
    "        self.ffn = FFN(n_embd, dropout)\n",
    "\n",
    "        # RMSNorm is designed to be \"shift-invariant\" (it centers data around 0), in Diffusion models, injecting the shift (beta) back in after normalization is a powerful way to tell the network about the noise level\n",
    "        if use_time:\n",
    "            self.time_ffn = nn.Sequential(\n",
    "                nn.Linear(n_embd, 2 * n_embd),\n",
    "                SwiGLU(), # SwiGLU will half the feature dimension\n",
    "                nn.Linear(n_embd, 4*n_embd)\n",
    "            )\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        if self.use_time and time_emb is not None:\n",
    "            time_params = self.time_ffn(time_emb) # [B, e_embd]@[n_embd, 4*n_embd]=[B, 4*n_embd]\n",
    "            shift1, scale1, shift2, scale2 = time_params.chunk(4, dim=-1) # [B, n_embd]\n",
    "\n",
    "            h = self.rms_norm_1(x) * (1 + scale1.unsqueeze(1)) + shift1.unsqueeze(1) # [B, T, C]*[B, 1, C]+[B, 1, C]=[B, T, C]\n",
    "            x = x + self.attn(h)\n",
    "            h = self.rms_norm_2(x) * (1 + scale2.unsqueeze(1)) + shift2.unsqueeze(1) # [B, T, C]*[B, 1, C]+[B, 1, C]=[B, T, C]\n",
    "            x = x + self.ffn(h) # [B, T, C]\n",
    "        else:\n",
    "            x = x + self.attn(self.rms_norm_1(x))\n",
    "            x = x + self.ffn(self.rms_norm_2(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "052e800f",
   "metadata": {
    "id": "052e800f"
   },
   "outputs": [],
   "source": [
    "# Full MDLM\n",
    "\n",
    "class MDLM(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size,\n",
    "            n_embd,\n",
    "            n_head,\n",
    "            n_block,\n",
    "            block_size,\n",
    "            dropout=0.1,\n",
    "            use_time = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block_size = block_size\n",
    "        self.use_time = use_time\n",
    "        self.tok_emb = nn.Embedding(vocab_size, n_embd)\n",
    "        if use_time:\n",
    "            self.time_emb = SinusoidalTimeEmbedding(n_embd)\n",
    "            self.time_proj = nn.Sequential(\n",
    "                nn.Linear(n_embd, 2*n_embd),\n",
    "                SwiGLU(),\n",
    "                nn.Linear(n_embd, n_embd)\n",
    "            )\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(n_embd, n_head, dropout, use_time) for _ in range(n_block)\n",
    "        ])\n",
    "\n",
    "        self.rms_norm_final = nn.RMSNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size, bias=False)\n",
    "\n",
    "        # tie input and output embedding weights\n",
    "        self.lm_head.weight = self.tok_emb.weight\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        print(f'Model has {n_params/1e6:.2f}M parameters.')\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        elif isinstance(module, nn.RMSNorm):\n",
    "            torch.nn.init.ones_(module.weight)\n",
    "\n",
    "    def forward(self, x, t=None):\n",
    "        B, T = x.shape\n",
    "\n",
    "        tok_emb = self.tok_emb(x) # [B, T, n_embd]\n",
    "        h = self.dropout(tok_emb)\n",
    "\n",
    "        if self.use_time and t is not None:\n",
    "            t_emb = self.time_emb(t) # [B, n_embd]\n",
    "            t_emb = self.time_proj(t_emb) # [B, n_embd]\n",
    "        else:\n",
    "            t_emb = None\n",
    "\n",
    "        for block in self.blocks:\n",
    "            h = block(h, t_emb)\n",
    "\n",
    "        h = self.rms_norm_final(h)\n",
    "        logits = self.lm_head(h) # [B, T, V]\n",
    "\n",
    "        # Make sure model doesn't learn the behavior of predicting a mask token. Aligns with inference\n",
    "        logits[:, :, MASK_TOKEN] = float('-inf')\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdd6973b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdd6973b",
    "outputId": "a867702d-82a4-4f13-9d7c-c19e384d9523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 39.65M parameters.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "\n",
    "model = MDLM(\n",
    "    vocab_size=final_vocab_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_block=n_blocks,\n",
    "    block_size=block_size,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9314bc1",
   "metadata": {
    "id": "b9314bc1"
   },
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "CKPT_DIR = './ckpt'\n",
    "CKPT_PATH = os.path.join(CKPT_DIR, 'latest.pt')\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "def train(model, dataloader, epochs, lr=3e-4, warmup_steps=1000, save_interval_minutes=20):\n",
    "    \"\"\"\n",
    "    Training loop with bfloat16 AMP, auto-resume, periodic checkpointing,\n",
    "    torch.compile, and optimized logging to minimize CPU-GPU synchronization.\n",
    "    \"\"\"\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    total_steps = len(dataloader) * epochs\n",
    "\n",
    "    def lr_lambda(step):\n",
    "        if step < warmup_steps:\n",
    "            return step / warmup_steps\n",
    "        else:\n",
    "            progress = (step - warmup_steps) / (total_steps - warmup_steps)\n",
    "            return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "    # ============================================================\n",
    "    # AUTO-RESUME: Check for existing checkpoint\n",
    "    # ============================================================\n",
    "    start_epoch = 0\n",
    "    global_step = 0\n",
    "    losses = []\n",
    "\n",
    "    if os.path.exists(CKPT_PATH):\n",
    "        print(f\"📂 Found checkpoint at {CKPT_PATH}\")\n",
    "        checkpoint = torch.load(CKPT_PATH, map_location=device, weights_only=False)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        global_step = checkpoint['global_step']\n",
    "        losses = checkpoint['losses']\n",
    "        print(f\"✅ Resuming from epoch {start_epoch + 1}, step {global_step}\")\n",
    "    else:\n",
    "        print(\"🆕 No checkpoint found, starting fresh\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # ============================================================\n",
    "    # SAVE CHECKPOINT FUNCTION\n",
    "    # ============================================================\n",
    "    def save_checkpoint(epoch, step):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'global_step': step,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'losses': losses,\n",
    "        }, CKPT_PATH)\n",
    "        print(f\"\\n💾 Checkpoint saved at epoch {epoch + 1}, step {step}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # TRAINING LOOP\n",
    "    # ============================================================\n",
    "    model.train()\n",
    "    device_type = device.type\n",
    "    print(f\"Training with bfloat16 on {device_type}\")\n",
    "    \n",
    "    # 1. COMPILE MODEL (Huge speedup for small models on 5090)\n",
    "    print(\"Compiling model...\")\n",
    "    model = torch.compile(model)\n",
    "    print(\"Model compiled.\")\n",
    "\n",
    "    last_save_time = time.time()\n",
    "    \n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "        # We will track epoch loss by accumulating locally\n",
    "        running_loss_sum = 0.0\n",
    "        running_steps = 0\n",
    "        \n",
    "        pbar = tqdm(dataloader, desc=f'Epoch {epoch + 1}/{epochs}')\n",
    "        \n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            x_0 = batch.to(device)\n",
    "\n",
    "            with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n",
    "                loss = compute_loss(model, x_0, MASK_TOKEN)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            \n",
    "            global_step += 1\n",
    "\n",
    "            # OPTIMIZED LOGGING: Only sync to CPU every 20 steps\n",
    "            if batch_idx % 20 == 0:\n",
    "                # This .item() forces a sync, but doing it 1/20th as often\n",
    "                # frees the GPU to run ahead.\n",
    "                current_loss = loss.item()\n",
    "                losses.append(current_loss)\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({\n",
    "                    'loss': f'{current_loss:.4f}',\n",
    "                    'lr': f'{scheduler.get_last_lr()[0]:.2e}'\n",
    "                })\n",
    "                \n",
    "                # Accumulate for average\n",
    "                running_loss_sum += current_loss\n",
    "                running_steps += 1\n",
    "            \n",
    "            # === AUTOSAVE EVERY N MINUTES ===\n",
    "            if (time.time() - last_save_time) / 60 >= save_interval_minutes:\n",
    "                save_checkpoint(epoch, global_step)\n",
    "                last_save_time = time.time()\n",
    "\n",
    "        # End of Epoch Stats\n",
    "        avg_loss = running_loss_sum / max(1, running_steps)\n",
    "        max_allocated = torch.cuda.max_memory_allocated(0) / 1024**3\n",
    "        max_reserved = torch.cuda.max_memory_reserved(0) / 1024**3\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1} average loss (sampled): {avg_loss:.4f}\")\n",
    "        print(f\"Max VRAM Usage: {max_allocated:.2f} GB allocated / {max_reserved:.2f} GB reserved\")\n",
    "\n",
    "    save_checkpoint(epochs - 1, global_step)\n",
    "    print(\"✅ Training complete!\")\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c70c4b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c70c4b9",
    "outputId": "091f886c-0390-46cd-d046-d34db1f7c8b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🆕 No checkpoint found, starting fresh\n",
      "--------------------------------------------------\n",
      "Training with bfloat16 on cuda\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 157/157 [00:23<00:00,  6.61it/s, loss=4.7890, lr=4.23e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 average loss (sampled): 5.9168\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 157/157 [00:19<00:00,  7.94it/s, loss=4.1330, lr=8.94e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 average loss (sampled): 4.3498\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 157/157 [00:19<00:00,  7.93it/s, loss=3.9049, lr=1.36e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 average loss (sampled): 3.9672\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 157/157 [00:19<00:00,  7.92it/s, loss=3.5587, lr=1.84e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 average loss (sampled): 3.6240\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=3.2958, lr=2.31e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 average loss (sampled): 3.3745\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=3.1947, lr=2.78e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 average loss (sampled): 3.1788\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.8961, lr=3.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 average loss (sampled): 3.0451\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.8610, lr=3.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 average loss (sampled): 2.9616\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.9079, lr=2.99e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 average loss (sampled): 2.9090\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.8642, lr=2.99e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 average loss (sampled): 2.8422\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.7816, lr=2.98e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 average loss (sampled): 2.7888\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.7598, lr=2.97e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 average loss (sampled): 2.7981\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.6264, lr=2.96e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 average loss (sampled): 2.6899\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.5714, lr=2.95e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 average loss (sampled): 2.6762\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.6851, lr=2.94e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 average loss (sampled): 2.6023\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.5698, lr=2.92e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 average loss (sampled): 2.5534\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.5052, lr=2.91e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 average loss (sampled): 2.5504\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.6152, lr=2.89e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 average loss (sampled): 2.5029\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.5058, lr=2.87e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 average loss (sampled): 2.4964\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.4212, lr=2.85e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 average loss (sampled): 2.4973\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.4055, lr=2.83e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 average loss (sampled): 2.4726\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.6085, lr=2.80e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 average loss (sampled): 2.5012\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.5381, lr=2.78e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 average loss (sampled): 2.4038\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.3807, lr=2.75e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 average loss (sampled): 2.4028\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.2216, lr=2.72e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 average loss (sampled): 2.3670\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.3828, lr=2.69e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 average loss (sampled): 2.3982\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.4176, lr=2.66e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 average loss (sampled): 2.3573\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.2194, lr=2.63e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 average loss (sampled): 2.3312\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.3338, lr=2.59e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 average loss (sampled): 2.3579\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.3314, lr=2.56e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 average loss (sampled): 2.2602\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.1751, lr=2.52e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 average loss (sampled): 2.3085\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.3095, lr=2.48e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 average loss (sampled): 2.3217\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.3474, lr=2.44e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 average loss (sampled): 2.2964\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.3307, lr=2.40e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 average loss (sampled): 2.3125\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.3160, lr=2.36e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 average loss (sampled): 2.2696\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.2506, lr=2.32e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 average loss (sampled): 2.2280\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.0732, lr=2.28e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 average loss (sampled): 2.2452\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.1856, lr=2.24e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 average loss (sampled): 2.1487\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.1617, lr=2.19e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 average loss (sampled): 2.2200\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.3409, lr=2.15e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 average loss (sampled): 2.2352\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.1772, lr=2.10e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 average loss (sampled): 2.1808\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.0946, lr=2.05e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 average loss (sampled): 2.1833\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.1804, lr=2.01e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 average loss (sampled): 2.1303\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.1615, lr=1.96e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 average loss (sampled): 2.1200\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.0627, lr=1.91e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 average loss (sampled): 2.1005\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.0695, lr=1.86e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 average loss (sampled): 2.2021\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.2731, lr=1.81e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 average loss (sampled): 2.1835\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.0933, lr=1.76e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 average loss (sampled): 2.1466\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.1480, lr=1.72e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 average loss (sampled): 2.1122\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.2300, lr=1.67e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 average loss (sampled): 2.1563\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.9901, lr=1.61e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 average loss (sampled): 2.0924\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.0937, lr=1.56e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 average loss (sampled): 2.1362\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.1233, lr=1.51e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 average loss (sampled): 2.0759\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.0944, lr=1.46e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 average loss (sampled): 2.0996\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.1394, lr=1.41e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 average loss (sampled): 2.0170\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.2351, lr=1.36e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 average loss (sampled): 2.0843\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=1.8913, lr=1.31e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 average loss (sampled): 2.0583\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.1807, lr=1.26e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 average loss (sampled): 2.0865\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.1431, lr=1.21e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 average loss (sampled): 2.0726\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.4299, lr=1.16e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 average loss (sampled): 2.1097\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100:  25%|██▍       | 39/157 [00:06<01:07,  1.75it/s, loss=2.2055, lr=1.15e-04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Checkpoint saved at epoch 61, step 9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 157/157 [00:21<00:00,  7.40it/s, loss=1.9380, lr=1.12e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 average loss (sampled): 2.0548\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.2155, lr=1.07e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 average loss (sampled): 2.0831\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=1.9202, lr=1.02e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 average loss (sampled): 1.9770\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=1.9120, lr=9.72e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 average loss (sampled): 2.0023\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.0697, lr=9.26e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 average loss (sampled): 2.0543\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.9768, lr=8.79e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 average loss (sampled): 1.9940\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=1.9461, lr=8.34e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 average loss (sampled): 1.9525\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.0688, lr=7.89e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 average loss (sampled): 1.9594\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.0635, lr=7.45e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 average loss (sampled): 1.9828\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.8576, lr=7.02e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 average loss (sampled): 1.9635\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.8856, lr=6.60e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 average loss (sampled): 1.9954\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.0275, lr=6.19e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 average loss (sampled): 1.9926\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=1.9979, lr=5.79e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 average loss (sampled): 2.0028\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=1.9868, lr=5.39e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 average loss (sampled): 1.9969\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.0535, lr=5.01e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 average loss (sampled): 1.9784\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.1136, lr=4.64e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 average loss (sampled): 1.9938\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.0250, lr=4.29e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 average loss (sampled): 1.9053\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.0625, lr=3.94e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 average loss (sampled): 1.8859\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=1.7550, lr=3.61e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 average loss (sampled): 1.9130\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=1.9181, lr=3.28e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 average loss (sampled): 1.9025\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.9630, lr=2.98e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 average loss (sampled): 1.9060\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.0695, lr=2.68e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 average loss (sampled): 1.9778\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.9538, lr=2.40e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 average loss (sampled): 1.9612\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.0612, lr=2.14e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 average loss (sampled): 1.9221\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=2.1579, lr=1.88e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 average loss (sampled): 1.9228\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|██████████| 157/157 [00:19<00:00,  7.91it/s, loss=1.9228, lr=1.65e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 average loss (sampled): 1.9382\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.0568, lr=1.43e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 average loss (sampled): 1.8817\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.8105, lr=1.22e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 average loss (sampled): 1.8842\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.7718, lr=1.03e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 average loss (sampled): 1.8816\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.8815, lr=8.53e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 average loss (sampled): 1.9264\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.9095, lr=6.94e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 average loss (sampled): 1.9130\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=2.1005, lr=5.51e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 average loss (sampled): 1.9133\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.9680, lr=4.24e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 average loss (sampled): 1.8433\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.9837, lr=3.13e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 average loss (sampled): 1.8577\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.7629, lr=2.19e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 average loss (sampled): 1.8971\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.9010, lr=1.42e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 average loss (sampled): 1.9064\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.8184, lr=8.12e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 average loss (sampled): 1.9565\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|██████████| 157/157 [00:19<00:00,  7.87it/s, loss=1.9939, lr=3.73e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 average loss (sampled): 1.9266\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.9706, lr=1.03e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 average loss (sampled): 1.9205\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 157/157 [00:19<00:00,  7.90it/s, loss=1.8659, lr=8.77e-10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 average loss (sampled): 1.9156\n",
      "Max VRAM Usage: 18.17 GB allocated / 20.94 GB reserved\n",
      "\n",
      "💾 Checkpoint saved at epoch 100, step 15700\n",
      "✅ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "\n",
    "losses = train(model, dataloader, epochs=100, lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73d1607e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "73d1607e",
    "outputId": "f5274e5c-ab4e-4e1b-e5b3-e5725107e24b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss curve\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses, alpha=0.3)\n",
    "# Smoothed\n",
    "window = 100\n",
    "smoothed = np.convolve(losses, np.ones(window)/window, mode='valid')\n",
    "plt.plot(range(window-1, len(losses)), smoothed, 'r', linewidth=2)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ec6a37-314a-468d-b6e4-462a4a81219e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
